import pandas as pd
import numpy as np
from datetime import datetime


class InvestorPsychologyTracker:
    """
    24.1 ì‚¬ìš©ì í–‰ë™ ë¡œê·¸ & íŒë‹¨ ì¶”ì  ì‹œìŠ¤í…œ
    """

    def __init__(self):
        self.logs = []

    def record_action(self, action_type, strategy, market_condition, pnl, risk_change):
        """
        ì‚¬ìš©ì í–‰ë™ ê¸°ë¡
        """
        self.logs.append({
            "timestamp": pd.Timestamp.now(),
            "action_type": action_type,
            "strategy": strategy,
            "market_condition": market_condition,
            "pnl": pnl,
            "risk_change": risk_change
        })

    def get_behavior_df(self):
        return pd.DataFrame(self.logs)

    def analyze_behavioral_bias(self):
        """
        í–‰ë™ í¸í–¥ ë¶„ì„ (ê³¼ì‹ ë„, ì†ì‹¤ íšŒí”¼ ì„±í–¥, ë¹ˆë„ì„±)
        """
        df = self.get_behavior_df()
        if df.empty or len(df) < 2:
            return {"message": "ë¡œê·¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}

        overconfidence = ((df["pnl"] > 0) & (df["action_type"] == "ì¶”ê°€ë§¤ìˆ˜")).mean()
        loss_aversion = ((df["pnl"] < 0) & (df["action_type"] == "ë§¤ë„")).mean()

        df_sorted = df.sort_values("timestamp")
        time_diffs = df_sorted["timestamp"].diff().dropna()
        high_frequency = time_diffs.mean().total_seconds() if not time_diffs.empty else np.nan

        return {
            "ê³¼ì‹ ë„": round(overconfidence * 100, 2),
            "ì†ì‹¤ íšŒí”¼ ê²½í–¥": round(loss_aversion * 100, 2),
            "í–‰ë™ ë¹ˆë„ì„±": round(86400 / high_frequency, 2) if high_frequency and high_frequency > 0 else 0
        }

    def generate_heatmap_matrix(self):
        """
        íŒë‹¨ ì„±ê³µ/ì‹¤íŒ¨ íˆíŠ¸ë§µ ìƒì„±
        """
        df = self.get_behavior_df()
        if df.empty:
            return pd.DataFrame()

        df = df.copy()
        df["date"] = df["timestamp"].dt.date
        df["correct_decision"] = df["pnl"] > 0

        heatmap = df.groupby(["date", "strategy"])["correct_decision"].mean().unstack(fill_value=0)
        return heatmap


class PsychologicalReportGenerator:
    """
    24.2 íˆ¬ìì ì„±í–¥ ë¶„ë¥˜ ë° í”¼ë“œë°± ì¹´ë“œ ìƒì„±
    """

    def classify_investor_type(self, behavior_metrics):
        """
        ê³¼ì‹ ë„, ì†ì‹¤ íšŒí”¼ ê²½í–¥, í–‰ë™ ë¹ˆë„ì„± ê¸°ë°˜ ë¶„ë¥˜
        """
        oc = behavior_metrics.get("ê³¼ì‹ ë„", 0)
        la = behavior_metrics.get("ì†ì‹¤ íšŒí”¼ ê²½í–¥", 0)
        freq = behavior_metrics.get("í–‰ë™ ë¹ˆë„ì„±", 0)

        if oc > 70 and freq > 5:
            return "ì§ ì‚¬ì´ë¨¼ìŠ¤í˜• (ê³µê²©ì  + ê³ ë¹ˆë„)"
        elif la > 70:
            return "ë³€ë™ì„± íšŒí”¼í˜• (ë³´ìˆ˜ì  + ì†ì‹¤ íšŒí”¼)"
        elif freq < 2:
            return "ì›Œë Œ ë²„í•í˜• (ì €ë¹ˆë„ + ì¥ê¸° ë³´ìœ )"
        else:
            return "ì¤‘ë¦½í˜• íˆ¬ìì"

    def correlation_analysis(self, df):
        """
        ì „ëµ ë³€ê²½ â†” ìˆ˜ìµë¥  ìƒê´€ ë¶„ì„
        """
        if df.empty:
            return "ë°ì´í„° ë¶€ì¡±"

        df = df.copy()
        df["date"] = df["timestamp"].dt.date
        change_counts = df.groupby("date")["strategy"].nunique()
        daily_pnl = df.groupby("date")["pnl"].sum()

        merged = pd.DataFrame({
            "change_counts": change_counts,
            "daily_pnl": daily_pnl
        }).dropna()

        if merged.empty or merged.shape[0] < 2:
            return "ìƒê´€ ë¶„ì„ ë¶ˆê°€: ë°ì´í„° ë¶€ì¡±"

        corr = merged.corr().iloc[0, 1]
        return f"ì „ëµ ë³€ê²½ ë¹ˆë„ì™€ ìˆ˜ìµë¥ ì˜ ìƒê´€ê³„ìˆ˜: {round(corr, 3)}"


class StrategyRecommendationEngine:
    """
    24.3 ì‹¤ìˆ˜ íŒ¨í„´ ê¸°ë°˜ ì „ëµ ì œì–´ ì¶”ì²œ
    """

    def recommend_based_on_mistakes(self, df):
        """
        ì‹¤ìˆ˜ ê²½í–¥ ë¶„ì„ â†’ ì „ëµ ì¶”ì²œ
        """
        if df.empty:
            return "ì¶”ì²œ ë¶ˆê°€: ë¡œê·¸ ì—†ìŒ"

        df = df.copy()
        df["entry_loss"] = (df["pnl"] < 0) & (df["action_type"] == "ì§„ì…")
        entry_loss_rate = df["entry_loss"].mean()

        if entry_loss_rate > 0.5:
            return "ê³¼ë„í•œ ì¡°ê¸° ì§„ì… ê²½í–¥ â†’ 'ë¶„í• ë§¤ìˆ˜ ì „ëµ' ì¶”ì²œ"
        elif (df["pnl"] > 0).mean() < 0.3:
            return "ì „ëµ ì‹ ë¢°ë„ ë‚®ìŒ â†’ 'ì €ë³€ë™ ìì‚° ë¹„ì¤‘ í™•ëŒ€' ì¶”ì²œ"
        else:
            return "í˜„ì¬ ì „ëµ ìœ ì§€ ê°€ëŠ¥"

    def ghost_investor_replay(self, df, days_ago=14):
        """
        ê³¼ê±° íŒë‹¨ ì¬í˜„ ê¸°ëŠ¥ (2ì£¼ ì „ ê¸°ì¤€)
        """
        if df.empty:
            return pd.DataFrame()

        cutoff = pd.Timestamp.now() - pd.Timedelta(days=days_ago)
        replay_df = df[df["timestamp"] < cutoff]
        return replay_df.tail(10)
        
import streamlit as st

def run():
    st.header("ğŸ“˜ 24ë‹¨ì›. íˆ¬ìì ì‹¬ë¦¬ ì¶”ì  & í”¼ë“œë°± ì‹œìŠ¤í…œ")
    st.markdown("""
    â€œì‹œì¥ì€ ì‚¬ëŒì˜ êµ°ì¤‘ì‹¬ë¦¬ê°€ ë§Œë“ ë‹¤. íˆ¬ìì ìì‹ ë„ ë¶„ì„ ëŒ€ìƒì´ë‹¤.â€

    - 24.1 ì‚¬ìš©ì í–‰ë™ ë¡œê·¸ & íŒë‹¨ ì¶”ì   
      ë§¤ë§¤ íƒ€ì´ë°, ì „ëµ ë³€ê²½ ë¹ˆë„, ë¦¬ìŠ¤í¬ íšŒí”¼ íŒ¨í„´ ê¸°ë¡  
      â€œì‹œì¥ í•˜ë½ ì‹œ ë§¤ë„ â†‘â€, â€œìˆ˜ìµ ìƒìŠ¹ ì‹œ ê³¼ì‹ â€ ìë™ ì¶”ì¶œ  
      ì˜ì‚¬ê²°ì • í¸í–¥ ì ìˆ˜í™” (ê³¼ì‹ ë„, ì†ì‹¤ íšŒí”¼, ì¶”ì„¸ ë¹ˆë„)

    - 24.2 ì‹¬ë¦¬ í”¼ë“œë°± ì¹´ë“œ & íŒë‹¨ ì„±í–¥ ë¦¬í¬íŠ¸  
      íˆ¬ì ì„±í–¥ ìœ í˜• ë¶„ë¥˜ (ì›Œë Œ ë²„í•í˜•, ì§ ì‚¬ì´ë¨¼ìŠ¤í˜• ë“±)  
      í–‰ë™-ì„±ê³¼ ìƒê´€ êµ¬ì¡° ë¶„ì„  
      íŒë‹¨ íˆíŠ¸ë§µ ì œê³µ (ì„±ê³µ/ì‹¤íŒ¨ êµ¬ê°„ ì‹œê°í™”)

    - 24.3 ì‹¬ë¦¬ ê¸°ë°˜ ì „ëµ ì¶”ì²œ ì‹œìŠ¤í…œ  
      ê³¼ê±° ì‹¤ìˆ˜ ìœ í˜• ë¶„ì„ â†’ ì „ëµ ì œì–´ êµ¬ì¡° ì¶”ì²œ  
      ì˜ˆ: â€œì§„ì… ì¡°ê¸‰ì¦ â†’ ë¶„í• ë§¤ìˆ˜ ì „ëµ ì¶”ì²œâ€  
      ê³ ìŠ¤íŠ¸ íˆ¬ìì ë¦¬í”Œë ˆì´ ê¸°ëŠ¥ (ê³¼ê±° íŒë‹¨ ì¬í˜„)
    """)