import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from ruptures import Binseg
from typing import Dict, List, Optional


# 16.1 ìƒìŠ¹/ë³´í•©/í•˜ë½ ì‹œë‚˜ë¦¬ì˜¤ í™•ë¥  ì¶”ì •
def estimate_market_scenarios(market_factors: Dict[str, float]) -> Dict[str, float]:
    factors = np.array(list(market_factors.values()))
    scaler = MinMaxScaler()
    norm = scaler.fit_transform(factors.reshape(1, -1))[0]

    # ì˜ˆì‹œ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í™•ë¥  ê³„ì‚°
    prob_up = norm[0] * 0.5 + (1 - norm[1]) * 0.3 + norm[2] * 0.2
    prob_flat = (1 - abs(norm[0] - 0.5)) * 0.6
    prob_down = 1.0 - prob_up - prob_flat

    # ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ë³´ì •
    prob_up = max(0, min(1, prob_up))
    prob_flat = max(0, min(1, 1 - prob_up - max(0, prob_down)))
    prob_down = max(0, min(1, 1 - prob_up - prob_flat))

    return {
        'up': round(prob_up, 3),
        'flat': round(prob_flat, 3),
        'down': round(prob_down, 3)
    }


# 16.2 ì „ëµêµ°ë³„ ì‹œë‚˜ë¦¬ì˜¤ ìµœì í™”
def get_strategy_for_scenario(scenario: str) -> Dict[str, List[str]]:
    mapping = {
        'up': {
            'name': 'ê³ ì„±ì¥ + ëª¨ë©˜í…€ ì „ëµ',
            'components': ['Growth Stocks', 'Momentum Leaders']
        },
        'flat': {
            'name': 'ê· í˜•í˜• ì „ëµ',
            'components': ['Low Volatility', 'High ROE']
        },
        'down': {
            'name': 'ê³ ë°°ë‹¹ + ë³€ë™ì„± í—·ì§• ì „ëµ',
            'components': ['Dividend Stocks', 'Inverse ETFs', 'Volatility Hedge']
        }
    }
    return mapping.get(scenario, {})


# 16.3 ì „ëµ ì¤‘ë³µ ì œê±° ë° ë¶„ì‚° ê°•í™”
def remove_overlaps(strategies: Dict[str, Dict]) -> Dict[str, Dict]:
    seen = set()
    for scenario, strat in strategies.items():
        filtered = [s for s in strat.get('components', []) if s not in seen]
        strategies[scenario]['components'] = filtered
        seen.update(filtered)
    return strategies


# 16.4 ì‹œë‚˜ë¦¬ì˜¤ ì „í™˜ ê°ì§€ ì—”ì§„ (Bayesian Change Point)
def detect_scenario_shift(ts_data: List[float], pen: int = 5) -> Optional[int]:
    try:
        model = Binseg(model="l2").fit(ts_data)
        change_points = model.predict(pen=pen)
        return change_points[-1] if change_points else None
    except Exception:
        return None


# 16.5 ì „ëµ íë¦„ë„: ë§ˆë¥´ì½”í”„ í™•ë¥  ê¸°ë°˜ ì „ì´ êµ¬ì¡°
def generate_scenario_markov(prob_dict: Dict[str, float]) -> Dict[str, Dict[str, float]]:
    # ê° ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œì˜ ì „ì´ í™•ë¥  (ë‹¨ìˆœ êµ¬ì¡° ê¸°ë°˜)
    return {
        'up': {
            'flat': round(1 - prob_dict['up'], 3),
            'down': round(prob_dict['down'], 3)
        },
        'flat': {
            'up': round(prob_dict['up'], 3),
            'down': round(prob_dict['down'], 3)
        },
        'down': {
            'flat': round(prob_dict['flat'], 3),
            'up': round(prob_dict['up'], 3)
        }
    }


# âœ… ìµœì¢… í†µí•© ì‹¤í–‰ í•¨ìˆ˜
def run_scenario_branching(market_factors: Dict[str, float], recent_ts: List[float]) -> Dict:
    probs = estimate_market_scenarios(market_factors)
    
    strategies = {
        'up': get_strategy_for_scenario('up'),
        'flat': get_strategy_for_scenario('flat'),
        'down': get_strategy_for_scenario('down')
    }
    strategies = remove_overlaps(strategies)
    
    shift_point = detect_scenario_shift(recent_ts)
    markov_map = generate_scenario_markov(probs)

    return {
        'scenario_probabilities': probs,
        'recommended_strategies': strategies,
        'last_detected_shift_index': shift_point,
        'markov_transition_map': markov_map
    }
    
import streamlit as st

def run():
    st.header("ğŸ“˜ 16ë‹¨ì›. ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸° ì „ëµ ì‹œìŠ¤í…œ")
    st.markdown("""
    â€œí•œ ê°€ì§€ë§Œ ë¯¿ëŠ” ê±´ ë„ë°•ì´ë‹¤. ëª¨ë“  ê²½ë¡œë¥¼ ì˜ˆì¸¡í•˜ê³  ì¤€ë¹„í•´ì•¼ ì‚°ë‹¤.â€

    - 16.1 ìƒìŠ¹/ë³´í•©/í•˜ë½ ì‹œë‚˜ë¦¬ì˜¤ í™•ë¥  ì¶”ì •  
      ì£¼ìš” ë³€ìˆ˜ ê¸°ë°˜ í™•ë¥  ì‚°ì¶œ (ì˜ˆ: P(up)=62%)  
      ë¶„ê¸°ë³„ ê¸°ëŒ€ ìˆ˜ìµë¥ ê³¼ ë¦¬ìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜ í¬í•¨

    - 16.2 ì „ëµêµ°ë³„ ì‹œë‚˜ë¦¬ì˜¤ ìµœì í™”  
      ìƒìŠ¹: ê³ ì„±ì¥ + ëª¨ë©˜í…€  
      í•˜ë½: ê³ ë°°ë‹¹ + ë³€ë™ì„± í—·ì§•  
      ì‹œë‚˜ë¦¬ì˜¤ë³„ ì „ëµ íŒ¨í‚¤ì§€ ì œê³µ

    - 16.3 ì „ëµ ê°„ ì¤‘ë³µ ì œê±° ë° ë¶„ì‚° ê°•í™”  
      ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¤‘ë³µ ì¢…ëª© ì œê±°  
      ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ìƒí˜¸ë³´ì™„ë„ ê°•í™”

    - 16.4 ì‹œë‚˜ë¦¬ì˜¤ ì „í™˜ íƒì§€ ì—”ì§„  
      ì‹œì¥ì‹¬ë¦¬, ìˆ˜ê¸‰, ë§¤í¬ë¡œ ë³€í™” ê°ì§€  
      Bayesian Change Point Detection í™œìš©  
      â€œí•˜ë½ ì‹œë‚˜ë¦¬ì˜¤ ì „í™˜ ê°ì§€ â†’ ì „ëµ B ì „í™˜ ì œì•ˆâ€

    - 16.5 ì „ëµ íë¦„ ë§µ (Markov í”Œë¡œìš°)  
      êµ­ë©´ íë¦„(ìƒìŠ¹â†’í˜¼ì¡°â†’í•˜ë½) ì‹œê°í™”  
      ë‹¤ìŒ ì „í™˜ í™•ë¥  í‘œì‹œ (ì˜ˆ: 67%)
    """)