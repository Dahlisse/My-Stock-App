# module_05.py

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
from wordcloud import WordCloud
from datetime import datetime, timedelta

# ì‹œë“œ ê³ ì • (ìž¬í˜„ ê°€ëŠ¥ì„± í™•ë³´)
np.random.seed(42)
random.seed(42)

# 5.1 ë‰´ìŠ¤Â·ê°ì„± ë¶„ì„ (ë”ë¯¸ ê¸°ë°˜)
def simulate_news_sentiment(n=50):
    keywords = ["ê¸ˆë¦¬", "í™˜ìœ¨", "ì „ìŸ", "ì„±ìž¥", "ë¦¬ì„¸ì…˜", "ìˆ˜ì¶œ", "ë°˜ë„ì²´", "ETF", "í…ŒìŠ¬ë¼", "ì—°ì¤€"]
    sentiment_scores = np.random.normal(loc=0.1, scale=0.5, size=n)
    summary = []
    keyword_freq = {}

    for i in range(n):
        score = sentiment_scores[i]
        keyword = random.choice(keywords)
        keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
        sentiment = "ê¸ì •" if score > 0.1 else "ë¶€ì •" if score < -0.1 else "ì¤‘ë¦½"
        summary.append({
            "ë‰´ìŠ¤": f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ ì œëª© {i+1}",
            "ê°ì„±": sentiment,
            "ì ìˆ˜": float(score)
        })
    return pd.DataFrame(summary), keyword_freq

def plot_wordcloud(keyword_freq):
    wc = WordCloud(background_color='white', width=800, height=300, font_path=None)
    wc.generate_from_frequencies(keyword_freq)
    plt.figure(figsize=(10, 3))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.tight_layout()
    st.pyplot(plt.gcf())
    plt.clf()  # ì¤‘ì²© ë°©ì§€

# 5.2 ìˆ˜ê¸‰ ë° ì™¸ë¶€ ë³€ìˆ˜ (ë”ë¯¸)
def simulate_macro_variables():
    today = datetime.today()
    dates = pd.date_range(end=today, periods=90)

    data = {
        "ê¸ˆë¦¬": np.random.normal(3.0, 0.2, len(dates)),
        "í™˜ìœ¨": np.random.normal(1300, 20, len(dates)),
        "ìœ ê°€": np.random.normal(75, 5, len(dates)),
        "CPI": np.random.normal(3.5, 0.3, len(dates)),
        "Fear-Greed Index": np.random.uniform(0, 100, len(dates))
    }
    return pd.DataFrame(data, index=dates)

def plot_macro_time_series(df):
    st.subheader("ðŸ“Š ë§¤í¬ë¡œ ë³€ìˆ˜ ì‹œê³„ì—´")
    for col in df.columns:
        st.line_chart(df[[col]])

# 5.3 ì‹¬ë¦¬ ì ìˆ˜í™”
def compute_sentiment_score(news_df, macro_df):
    try:
        pos_ratio = (news_df['ê°ì„±'] == 'ê¸ì •').mean()
        fear_index = float(macro_df['Fear-Greed Index'].iloc[-1])
        vol_spike = np.std(macro_df['ìœ ê°€']) > 7 or np.std(macro_df['í™˜ìœ¨']) > 25

        base_score = pos_ratio * 100 - fear_index * 0.3
        score = max(0, min(100, base_score - 10 if vol_spike else base_score))
        label = "ê³¼ì—´" if score > 70 else "ì¹¨ì²´" if score < 30 else "ì¤‘ë¦½"
    except Exception as e:
        score = 50.0
        label = "ì¤‘ë¦½"
        st.error(f"ì‹¬ë¦¬ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
    return score, label

# ì „ì²´ ëª¨ë“ˆ ì‹¤í–‰
def run():
    st.header("ðŸ“˜ 5ë‹¨ì›. ì‹œìž¥ ì‹¬ë¦¬ ë° ì™¸ë¶€ ìš”ì¸ ë¶„ì„")

    # 5.1 ë‰´ìŠ¤ ê°ì„± ë¶„ì„
    st.subheader("ðŸ“° ë‰´ìŠ¤ í‚¤ì›Œë“œ ë° ê°ì„± ë¶„ì„")
    news_df, keyword_freq = simulate_news_sentiment()
    st.dataframe(news_df.head(10))
    st.write("ðŸ“Œ í‚¤ì›Œë“œ ê¸°ë°˜ WordCloud")
    plot_wordcloud(keyword_freq)

    # 5.2 ìˆ˜ê¸‰ ë° ë§¤í¬ë¡œ ë³€ìˆ˜
    st.subheader("ðŸ“ˆ ìˆ˜ê¸‰ ë° ì™¸ë¶€ ë³€ìˆ˜ ì‹œê³„ì—´")
    macro_df = simulate_macro_variables()
    plot_macro_time_series(macro_df)

    # 5.3 ì‹¬ë¦¬ ì ìˆ˜í™”
    st.subheader("ðŸ’¡ ì‹œìž¥ ì‹¬ë¦¬ ìŠ¤ì½”ì–´ë§")
    score, label = compute_sentiment_score(news_df, macro_df)
    st.metric("ì‹œìž¥ ì‹¬ë¦¬ ë¯¼ê°ë„ ì ìˆ˜", f"{score:.2f} / 100")
    st.write(f"êµ°ì¤‘ ì‹¬ë¦¬ ìƒíƒœ íŒë‹¨: **{label} ìƒíƒœ**")

    # ë©”ì‹œì§€ ì¶œë ¥
    if label == "ê³¼ì—´":
        st.warning("âš  í˜„ìž¬ ì‹œìž¥ì€ ê³¼ì—´ ìƒíƒœë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ë°©ì–´ì  ì „ëžµì„ ê³ ë ¤í•˜ì„¸ìš”.")
    elif label == "ì¹¨ì²´":
        st.info("ðŸ“‰ í˜„ìž¬ ì‹œìž¥ì€ ì¹¨ì²´ ë¶„ìœ„ê¸°ìž…ë‹ˆë‹¤. ì•ˆì •í˜• ì „ëžµì´ ì í•©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    else:
        st.success("ì‹œìž¥ ì‹¬ë¦¬ê°€ ì•ˆì •ì ì´ë©° ì¤‘ë¦½ì ìž…ë‹ˆë‹¤.")

    return score