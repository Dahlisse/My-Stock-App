import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# 17.1 ì „ëµ ë¹„êµ ë©”íŠ¸ë¦­
def compare_strategies(strategies_data):
    # strategies_data: dict[ì „ëµëª…] = {'return': [], 'mdd': [], 'sharpe': [], ...}
    df = pd.DataFrame(strategies_data).T
    df['calmar'] = df['return'] / (abs(df['mdd']) + 1e-6)  # divide-by-zero íšŒí”¼
    df = df[['return', 'mdd', 'sharpe', 'calmar']].round(4)
    return df

# 17.2 ì‚¬ìš©ì ì„±í–¥ ê¸°ë°˜ ì „ëµ ì í•©ë„ ì ìˆ˜í™”
def score_by_user_profile(strategy_df, user_type='ì¤‘ë¦½í˜•'):
    weights = {
        'ë³´ìˆ˜í˜•': {'return': 0.2, 'mdd': -0.4, 'sharpe': 0.3, 'calmar': 0.1},
        'ì¤‘ë¦½í˜•': {'return': 0.3, 'mdd': -0.3, 'sharpe': 0.3, 'calmar': 0.1},
        'ê³µê²©í˜•': {'return': 0.5, 'mdd': -0.1, 'sharpe': 0.3, 'calmar': 0.1}
    }
    w = weights.get(user_type, weights['ì¤‘ë¦½í˜•'])

    scaler = MinMaxScaler()
    norm_values = scaler.fit_transform(strategy_df)
    norm_df = pd.DataFrame(norm_values, columns=strategy_df.columns, index=strategy_df.index)

    score = norm_df.apply(lambda row: sum(row[k]*w[k] for k in w), axis=1)
    strategy_df['ì í•©ë„(0~1)'] = score.fillna(0).round(3)
    return strategy_df

# 17.3 ì „ëµ ìš°ìœ„ ì „í™˜ ê°ì§€
def detect_strategy_leader(history_data):
    if history_data is None or history_data.empty:
        return None
    mean_returns = history_data.rolling(window=20).mean()
    leader = mean_returns.idxmax(axis=1)
    return leader

# 17.4 ì „ëµ ì„ íƒ í•´ì„¤ ìƒì„±ê¸°
def explain_strategy_choice(strategy_name, strategy_df):
    if strategy_name not in strategy_df.index:
        return f"{strategy_name} ì „ëµ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    row = strategy_df.loc[strategy_name]
    parts = []
    if row['sharpe'] > 1:
        parts.append("ìˆ˜ìµ ëŒ€ë¹„ ë¦¬ìŠ¤í¬ê°€ ìš°ìˆ˜í•˜ë©°")
    if abs(row['mdd']) < 0.1:
        parts.append("ë‚™í­ì´ ì‘ì•„ ì•ˆì •ì ì…ë‹ˆë‹¤.")
    else:
        parts.append("ë‚™í­ì´ í¬ì§€ë§Œ ìˆ˜ìµë¥ ì´ ì´ë¥¼ ìƒì‡„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    return f"{strategy_name} ì „ëµì€ " + ' '.join(parts)

# 17.5 í–‰ë™ê²½ì œ ê¸°ë°˜ ì‹¬ë¦¬ ë³´ì •
def apply_behavioral_adjustment(strategy_df, bias_type=None):
    if bias_type not in ['loss_aversion', 'overconfidence', 'herding']:
        return strategy_df

    adjustment = strategy_df.copy()
    if 'ì í•©ë„(0~1)' not in adjustment.columns:
        return adjustment

    if bias_type == 'loss_aversion':
        adjustment['ì í•©ë„(0~1)'] -= adjustment['mdd'].abs() * 0.3
    elif bias_type == 'overconfidence':
        adjustment['ì í•©ë„(0~1)'] += adjustment['return'] * 0.2
    elif bias_type == 'herding':
        adjustment['ì í•©ë„(0~1)'] += adjustment['sharpe'] * 0.1

    adjustment['ì í•©ë„(0~1)'] = adjustment['ì í•©ë„(0~1)'].clip(0, 1).round(3)
    return adjustment

# ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜
def run_strategy_comparator(strategies_data, user_type='ì¤‘ë¦½í˜•', bias_type=None, history_data=None):
    try:
        comparison_df = compare_strategies(strategies_data)
        scored_df = score_by_user_profile(comparison_df.copy(), user_type)

        if bias_type:
            scored_df = apply_behavioral_adjustment(scored_df, bias_type)

        best_strategy = scored_df['ì í•©ë„(0~1)'].idxmax()
        explanation = explain_strategy_choice(best_strategy, scored_df)

        leader_flow = detect_strategy_leader(history_data) if history_data is not None else None

        return {
            'scored_df': scored_df,
            'best_strategy': best_strategy,
            'explanation': explanation,
            'leader_flow': leader_flow
        }
    
    except Exception as e:
        # ì—ëŸ¬ ë¡œê¹… í•„ìš”ì‹œ ì—¬ê¸° ì‚½ì…
        return {
            'error': str(e),
            'scored_df': None,
            'best_strategy': None,
            'explanation': None,
            'leader_flow': None
        }
        
import streamlit as st

def run():
    st.header("ğŸ“˜ 17ë‹¨ì›. ì „ëµ ë¹„êµ & íŠ¸ë ˆì´ë“œì˜¤í”„ ì‹œìŠ¤í…œ")
    st.markdown("""
    â€œë‹¹ì‹ ì´ ë¬´ì—‡ì„ ì„ íƒí•˜ëŠëƒê°€ ì•„ë‹ˆë¼, ë‹¹ì‹ ì´ ì–´ë–¤ ì‚¬ëŒì¸ì§€ê°€ ì„ íƒì„ ë§Œë“ ë‹¤.â€

    - 17.1 ì „ëµ ë¹„êµ ì‹œê°í™”  
      ìˆ˜ìµë¥ , MDD, Sharpe, Calmar, ë³€ë™ì„± ë¹„êµ  
      ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ë³„ ê°•ì¡° ì˜µì…˜ (ìˆ˜ìµ vs ì•ˆì •)

    - 17.2 ì‚¬ìš©ì ì„±í–¥ ê¸°ë°˜ ì „ëµ ì í•©ë„ ì¡°ì •  
      ë³´ìˆ˜í˜•: ì†ì‹¤ íšŒí”¼ ì „ëµ ìš°ì„   
      ê³µê²©í˜•: ì„±ì¥+ë³€ë™ì„± ìˆ˜ìš© ì „ëµ  
      ì í•©ë„ ìŠ¤ì½”ì–´ ì‹œê°í™” í¬í•¨

    - 17.3 ì „ëµ ìš°ìœ„ ì „í™˜ ê°ì§€  
      ì‹œì¥ ë³€í™”ì— ë”°ë¥¸ ìš°ìœ„ ì „ëµ ìë™ íŒë³„  
      ìš°ìœ„ íë¦„ ì‹œê³„ì—´ ì°¨íŠ¸ ì œê³µ

    - 17.4 ì „ëµ ì„ íƒ í•´ì„¤ ìƒì„±ê¸° (Explainable AI)  
      ì‚¬ìš©ì ì…ë ¥ + ì‹œì¥ ì¡°ê±´ ë¶„ì„ í›„ ì œì•ˆ  
      â€œë‹¹ì‹  ì¡°ê±´ì— ìµœì  ì „ëµì€ Aì…ë‹ˆë‹¤â€ ìì—°ì–´ ì„¤ëª…

    - 17.5 í–‰ë™ê²½ì œ ê¸°ë°˜ ì‹¬ë¦¬ ë³´ì • ê¸°ëŠ¥  
      ì†ì‹¤íšŒí”¼, ê³¼ì‹ , êµ°ì¤‘ì¶”ì¢… í¸í–¥ ë³´ì •  
      ì„±í–¥ë³„ í¸í–¥ ë³´ì • ê°€ì¤‘ì¹˜ ì ìš©
    """)